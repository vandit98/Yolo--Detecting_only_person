{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6975542,"sourceType":"datasetVersion","datasetId":4008248}],"dockerImageVersionId":30214,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-16T09:51:13.639827Z","iopub.execute_input":"2023-11-16T09:51:13.640215Z","iopub.status.idle":"2023-11-16T09:51:22.650253Z","shell.execute_reply.started":"2023-11-16T09:51:13.640121Z","shell.execute_reply":"2023-11-16T09:51:22.649206Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Task\nIn this notebook, we are trying to create an algorithm to classify a wide range (7, to be precise) of emotions based on facial expressions. For image classification, we have used the AlexNet DCNN.\n","metadata":{}},{"cell_type":"markdown","source":"# Why AlexNet?\nAlexNet was the winner of the 2012 ImageNet challenge. AlexNet had a remarkable intervention of using **relu** activation function to increase the efficiency by over 6 times by reducing the chances of Vanishing Gradient (VG) problems. \nAnother advantage AlexNet has is that overlappping maxpooling layers considerably improve model top-1 and top-5 accuracies.\n\nThe model consists of a total of 8 layers: five layers with a combination of max pooling followed by 3 fully connected layers. AlexNet was revolutionary in its field because it was the first model of its kind to introduce consecutive convolution layers in its architecture. \n![AlexNet Architecture](https://www.researchgate.net/profile/Nicola-Strisciuglio/publication/339756908/figure/fig5/AS:866265283457032@1583545146587/AlexNet-architecture-used-as-the-baseline-model-for-the-analysis-of-results-on-the.png)\n\nIt is important to note that AlexNet accepts input images of size: **227X227X3**\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport numpy as np\nimport pathlib\nimport datetime\n\n# printout versions\nprint(f\"Tensor Flow Version: {tf.__version__}\")\nprint(f\"numpy Version: {np.version.version}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:22.651908Z","iopub.execute_input":"2023-11-16T09:51:22.652230Z","iopub.status.idle":"2023-11-16T09:51:27.167015Z","shell.execute_reply.started":"2023-11-16T09:51:22.652200Z","shell.execute_reply":"2023-11-16T09:51:27.165969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating list of train images, classes and Class Names","metadata":{}},{"cell_type":"code","source":"data_dir = pathlib.Path(\"/kaggle/input/face-emotion-dataset/archive/train\")\nimage_count = len(list(data_dir.glob('*/*.png')))\nprint(image_count)\n# classnames in the dataset specified\nCLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\" ])\nprint(CLASS_NAMES)\n# print length of class names\noutput_class_units = len(CLASS_NAMES)\nprint(output_class_units)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:27.170068Z","iopub.execute_input":"2023-11-16T09:51:27.170618Z","iopub.status.idle":"2023-11-16T09:51:27.399635Z","shell.execute_reply.started":"2023-11-16T09:51:27.170588Z","shell.execute_reply":"2023-11-16T09:51:27.398683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(CLASS_NAMES)","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:27.402687Z","iopub.execute_input":"2023-11-16T09:51:27.403089Z","iopub.status.idle":"2023-11-16T09:51:27.408437Z","shell.execute_reply.started":"2023-11-16T09:51:27.403058Z","shell.execute_reply":"2023-11-16T09:51:27.407416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the AlexNet model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    # 1st conv\n  tf.keras.layers.Conv2D(96, (11,11),strides=(4,4), activation='relu', input_shape=(227, 227, 3)),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, strides=(2,2)),\n    # 2nd conv\n  tf.keras.layers.Conv2D(256, (11,11),strides=(1,1), activation='relu',padding=\"same\"),\n  tf.keras.layers.BatchNormalization(),\n     # 3rd conv\n  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n  tf.keras.layers.BatchNormalization(),\n    # 4th conv\n  tf.keras.layers.Conv2D(384, (3,3),strides=(1,1), activation='relu',padding=\"same\"),\n  tf.keras.layers.BatchNormalization(),\n    # 5th Conv\n  tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu',padding=\"same\"),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.MaxPooling2D(2, strides=(2, 2)),\n  # To Flatten layer\n  tf.keras.layers.Flatten(),\n  # To FC layer 1\n  tf.keras.layers.Dense(4096, activation='relu'),\n    # add dropout 0.5 ==> tf.keras.layers.Dropout(0.5),\n  #To FC layer 2\n  tf.keras.layers.Dense(4096, activation='relu'),\n    # add dropout 0.5 ==> tf.keras.layers.Dropout(0.5),\n  tf.keras.layers.Dense(output_class_units, activation='sigmoid')\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:27.409609Z","iopub.execute_input":"2023-11-16T09:51:27.409980Z","iopub.status.idle":"2023-11-16T09:51:30.993146Z","shell.execute_reply.started":"2023-11-16T09:51:27.409953Z","shell.execute_reply":"2023-11-16T09:51:30.992336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Data Generator Objects","metadata":{}},{"cell_type":"code","source":"data_dir2 = pathlib.Path(\"/kaggle/input/face-emotion-dataset/archive/test\")\n\nBATCH_SIZE = 32             # Can be of size 2^n, but not restricted to. for the better utilization of memory\nIMG_HEIGHT = 227            # input Shape required by the model\nIMG_WIDTH = 227             # input Shape required by the model\nSTEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n\n# Rescalingthe pixel values from 0~255 to 0~1 For RGB Channels of the image.\nimage_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n# training_data for model training\ntrain_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n                                                     batch_size=BATCH_SIZE,\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), #Resizing the raw dataset\n                                                     classes = list(CLASS_NAMES))\n\nval_data_gen = image_generator.flow_from_directory(directory=str(data_dir2),\n                                                     batch_size=BATCH_SIZE,\n                                                     shuffle=True,\n                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), #Resizing the raw dataset\n                                                     classes = list(CLASS_NAMES))","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:30.994457Z","iopub.execute_input":"2023-11-16T09:51:30.994766Z","iopub.status.idle":"2023-11-16T09:51:34.512536Z","shell.execute_reply.started":"2023-11-16T09:51:30.994737Z","shell.execute_reply":"2023-11-16T09:51:34.511529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:34.514072Z","iopub.execute_input":"2023-11-16T09:51:34.514511Z","iopub.status.idle":"2023-11-16T09:51:46.769376Z","shell.execute_reply.started":"2023-11-16T09:51:34.514471Z","shell.execute_reply":"2023-11-16T09:51:46.768056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compiling and Summarizing the Model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.SensitivityAtSpecificity(0.5), tf.keras.metrics.SpecificityAtSensitivity(0.5), tf.keras.metrics.AUC(curve='ROC')])\n\n# Summarizing the model architecture and printing it out\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:46.771085Z","iopub.execute_input":"2023-11-16T09:51:46.771452Z","iopub.status.idle":"2023-11-16T09:51:46.818511Z","shell.execute_reply.started":"2023-11-16T09:51:46.771420Z","shell.execute_reply":"2023-11-16T09:51:46.817568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model on 10 Epochs","metadata":{}},{"cell_type":"code","source":"import time\nstart = time.time()\nhistory = model.fit(\n      train_data_gen,\n      steps_per_epoch=STEPS_PER_EPOCH,\n      epochs=10,\n    validation_data=val_data_gen\n    \n)\n\n# Saving the model\nmodel.save('AlexNet_saved_model/')\nprint(\"Total time: \", time.time() - start, \"seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-11-16T09:51:46.819801Z","iopub.execute_input":"2023-11-16T09:51:46.820092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting the Metrics","metadata":{}},{"cell_type":"code","source":"def plot_hist(history):\n#     plt.plot(history.history[\"val_sensitivity_at_specificity\"], color='red')\n#     plt.plot(history.history[\"val_auc\"], color='blue')\n#     plt.plot(history.history[\"val_specificity_at_sensitivity\"], color='orange')\n#     plt.plot(history.history[\"val_accuracy\"],color='green')\n#     plt.plot(history.history[\"accuracy\"],color='olive')\n#     plt.plot(history.history[\"precision\"],color='violet')\n#     plt.plot(history.history[\"val_precision\"],color='purple')\n#     plt.plot(history.history[\"recall\"],color='cyan')\n#     plt.plot(history.history[\"val_recall\"],color='yellow')\n\n\n    \n    \n\n     \n    \n    \n    plt.title(\"Metrics\")\n    \n    \n    plt.legend([\"Sensitivity\",\"AUC\",\"Specificity\", \"Test Accuracy\", \"Train Accuracy\", \"Precision\", \"Test Precision\", \"Recall\", \"Test Recall\" ], bbox_to_anchor =(0.65, 1.00))\n    plt.show()\n\n\nplot_hist(history)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank you! Do check out my other kernels on Skin Cancer!","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/working/AlexNet_saved_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the saved model\nloaded_model = load_model('AlexNet_saved_model/')\n\n# Now you can use the loaded model to make predictions on new data\n# For example, if you have a test generator named test_data_gen\n# (make sure it's set up similarly to your training and validation generators),\n# you can use the following code:\n\npredictions = loaded_model.predict(val_data_gen)\n\n# 'predictions' will contain the model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation = loaded_model.evaluate(val_data_gen)\nprint(\"Test Loss:\", evaluation[0])\nprint(\"Test Accuracy:\", evaluation[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Replace 'your_directory' with the path to the directory you want to compress\ndirectory_to_compress = '/kaggle/working/AlexNet_saved_model'\n\n# Replace 'compressed_file.zip' with the desired name of the compressed file\ncompressed_file_path = '/kaggle/working/compressed_file.zip'\n\n# Create a zip file from the directory\nshutil.make_archive(compressed_file_path, 'zip', directory_to_compress)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}